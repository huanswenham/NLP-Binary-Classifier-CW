{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/ian/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/ian/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /home/ian/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Download required NLTK resources\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt_tab')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load dataset (Replace 'your_dataset.csv' with your actual dataset)\n",
    "train_df = pd.read_csv(\"../data/train_set.csv\")\n",
    "test_df = pd.read_csv(\"../data/dev_set.csv\")\n",
    "\n",
    "# Replace NaN values with empty strings\n",
    "train_df[\"text\"] = train_df[\"text\"].fillna(\"\")\n",
    "test_df[\"text\"] = test_df[\"text\"].fillna(\"\")\n",
    "\n",
    "\n",
    "# Preprocessing function\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    text = re.sub(r'\\W+', ' ', text)  # Remove punctuation and special characters\n",
    "    tokens = word_tokenize(text)  # Tokenize\n",
    "    tokens = [word for word in tokens if word not in stopwords.words(\"english\")]  # Remove stopwords\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# Apply preprocessing\n",
    "train_df[\"processed_text\"] = train_df[\"text\"].apply(preprocess_text)\n",
    "test_df[\"processed_text\"] = test_df[\"text\"].apply(preprocess_text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    7162\n",
       "1     375\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shuffle rows\n",
    "train_df = train_df.sample(frac=1).reset_index(drop=True)\n",
    "test_df = test_df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "X_train = train_df[\"processed_text\"]\n",
    "y_train = train_df[\"label\"]\n",
    "\n",
    "X_test = test_df[\"processed_text\"]\n",
    "y_test = test_df[\"label\"]\n",
    "\n",
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary Size: 25317\n"
     ]
    }
   ],
   "source": [
    "# Create Bag-of-Words features\n",
    "vectorizer = CountVectorizer(binary=False)  # Binary presence of words (can use binary=False for raw counts)\n",
    "X_train_bow = vectorizer.fit_transform(X_train)\n",
    "X_test_bow = vectorizer.transform(X_test)\n",
    "\n",
    "print(\"Vocabulary Size:\", len(vectorizer.get_feature_names_out()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9040114613180515\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.99      0.95      1895\n",
      "           1       0.46      0.06      0.11       199\n",
      "\n",
      "    accuracy                           0.90      2094\n",
      "   macro avg       0.69      0.53      0.53      2094\n",
      "weighted avg       0.87      0.90      0.87      2094\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[1881   14]\n",
      " [ 187   12]]\n"
     ]
    }
   ],
   "source": [
    "# Train Logistic Regression Model\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train_bow, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = clf.predict(X_test_bow)\n",
    "\n",
    "# Evaluate model\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Misclassified Example:\n",
      "Text: mari tte coetzee stofberg family vineyards whose mia chenin blanc 2016 garagiste trophy winner last year michelangelo awards recipient four platter stars mari tte chenin blanc 2016 says extremely proud current women winemakers industry especially considering juggling family along long working hours\n",
      "Original Text: \"Mari ? tte Coetzee from Stofberg Family Vineyards ( whose Mia Chenin Blanc 2016 was the garagiste trophy winner at last year 's Michelangelo Awards and the recipient of four Platter 's stars for the Mari ? tte Chenin Blanc 2016 ) , says : \"\" We can be extremely proud of the current women winemakers in our industry , especially considering most of them are juggling a family along with the long working hours .\"\n",
      "True Label: 1\n",
      "Predicted Label: 0\n"
     ]
    }
   ],
   "source": [
    "# Get misclassified examples\n",
    "df_test = X_test.reset_index(drop=True).to_frame()\n",
    "df_test[\"true_label\"] = y_test.reset_index(drop=True)\n",
    "df_test[\"predicted_label\"] = y_pred\n",
    "\n",
    "# Find one misclassified example\n",
    "misclassified = df_test[(df_test[\"true_label\"] == 1) & (df_test[\"predicted_label\"] == 0)]\n",
    "if not misclassified.empty:\n",
    "    example = misclassified.sample(1)  # Pick a random misclassified example\n",
    "    print(\"\\nMisclassified Example:\")\n",
    "    print(\"Text:\", example[\"processed_text\"].values[0])\n",
    "    print(\"Original Text:\", test_df.loc[example.index[0], \"text\"])\n",
    "    print(\"True Label:\", example[\"true_label\"].values[0])\n",
    "    print(\"Predicted Label:\", example[\"predicted_label\"].values[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average 'helping' count for class 0: 0.006422786931024853\n",
      "Average 'helping' count for class 1: 0.034666666666666665\n",
      "\n",
      "Average 'help' count for class 0: 0.041608489248813184\n",
      "Average 'help' count for class 1: 0.112\n",
      "\n",
      "Average 'love' count for class 0: 0.009494554593688915\n",
      "Average 'love' count for class 1: 0.029333333333333333\n",
      "\n",
      "Average 'fact' count for class 0: 0.01312482546774644\n",
      "Average 'fact' count for class 1: 0.010666666666666666\n",
      "\n",
      "Average 'christmas' count for class 0: 0.001117006422786931\n",
      "Average 'christmas' count for class 1: 0.042666666666666665\n"
     ]
    }
   ],
   "source": [
    "# Find how often the word 'help' appears per-class\n",
    "word_index = vectorizer.vocabulary_['helping']\n",
    "word_counts = X_train_bow[:, word_index].toarray().flatten()\n",
    "train_df[\"helping_count\"] = word_counts\n",
    "print(\"\\nAverage 'helping' count for class 0:\", train_df[train_df[\"label\"] == 0][\"helping_count\"].mean())\n",
    "print(\"Average 'helping' count for class 1:\", train_df[train_df[\"label\"] == 1][\"helping_count\"].mean())\n",
    "\n",
    "word_index = vectorizer.vocabulary_['help']\n",
    "word_counts = X_train_bow[:, word_index].toarray().flatten()\n",
    "train_df[\"help_count\"] = word_counts\n",
    "print(\"\\nAverage 'help' count for class 0:\", train_df[train_df[\"label\"] == 0][\"help_count\"].mean())\n",
    "print(\"Average 'help' count for class 1:\", train_df[train_df[\"label\"] == 1][\"help_count\"].mean())\n",
    "\n",
    "word_index = vectorizer.vocabulary_['love']\n",
    "word_counts = X_train_bow[:, word_index].toarray().flatten()\n",
    "train_df[\"love_count\"] = word_counts\n",
    "print(\"\\nAverage 'love' count for class 0:\", train_df[train_df[\"label\"] == 0][\"love_count\"].mean())\n",
    "print(\"Average 'love' count for class 1:\", train_df[train_df[\"label\"] == 1][\"love_count\"].mean())\n",
    "\n",
    "word_index = vectorizer.vocabulary_['fact']\n",
    "word_counts = X_train_bow[:, word_index].toarray().flatten()\n",
    "train_df[\"fact_count\"] = word_counts\n",
    "print(\"\\nAverage 'fact' count for class 0:\", train_df[train_df[\"label\"] == 0][\"fact_count\"].mean())\n",
    "print(\"Average 'fact' count for class 1:\", train_df[train_df[\"label\"] == 1][\"fact_count\"].mean())\n",
    "\n",
    "word_index = vectorizer.vocabulary_['christmas']\n",
    "word_counts = X_train_bow[:, word_index].toarray().flatten()\n",
    "train_df[\"christmas_count\"] = word_counts\n",
    "print(\"\\nAverage 'christmas' count for class 0:\", train_df[train_df[\"label\"] == 0][\"christmas_count\"].mean())\n",
    "print(\"Average 'christmas' count for class 1:\", train_df[train_df[\"label\"] == 1][\"christmas_count\"].mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Misclassified Example:\n",
    "Text: christmas celebration birth merely child child changed destiny humans forever celebration fact god wanted part human race took flesh blood became human like us also show unconditional love good deeds helping need help care human merciful\n",
    "Original Text: Christmas is celebration of the birth of not merely a child , but a child who changed the destiny of humans forever . It is celebration of the fact that God wanted to be a part of the human race and so he took on flesh and blood and became human like us . We can also show unconditional love through our good deeds and helping those who are in need of our help and care . Be human and merciful .\n",
    "True Label: 0\n",
    "Predicted Label: 1\n",
    "\n",
    "this example has original label (0,0) meaning two annotators marked it as non-PCL."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
