{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/ian/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/ian/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /home/ian/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Download required NLTK resources\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt_tab')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load dataset (Replace 'your_dataset.csv' with your actual dataset)\n",
    "train_df = pd.read_csv(\"../data/train_set.csv\")\n",
    "test_df = pd.read_csv(\"../data/dev_set.csv\")\n",
    "\n",
    "# Replace NaN values with empty strings\n",
    "train_df[\"text\"] = train_df[\"text\"].fillna(\"\")\n",
    "test_df[\"text\"] = test_df[\"text\"].fillna(\"\")\n",
    "\n",
    "\n",
    "# Preprocessing function\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    text = re.sub(r'\\W+', ' ', text)  # Remove punctuation and special characters\n",
    "    tokens = word_tokenize(text)  # Tokenize\n",
    "    tokens = [word for word in tokens if word not in stopwords.words(\"english\")]  # Remove stopwords\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# Apply preprocessing\n",
    "train_df[\"processed_text\"] = train_df[\"text\"].apply(preprocess_text)\n",
    "test_df[\"processed_text\"] = test_df[\"text\"].apply(preprocess_text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    7581\n",
       "1     794\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shuffle rows\n",
    "train_df = train_df.sample(frac=1).reset_index(drop=True)\n",
    "test_df = test_df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "X_train = train_df[\"processed_text\"]\n",
    "y_train = train_df[\"label\"]\n",
    "\n",
    "X_test = test_df[\"processed_text\"]\n",
    "y_test = test_df[\"label\"]\n",
    "\n",
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary Size: 26728\n"
     ]
    }
   ],
   "source": [
    "# Create Bag-of-Words features\n",
    "vectorizer = CountVectorizer(binary=False)  # Binary presence of words (can use binary=False for raw counts)\n",
    "X_train_bow = vectorizer.fit_transform(X_train)\n",
    "X_test_bow = vectorizer.transform(X_test)\n",
    "\n",
    "print(\"Vocabulary Size:\", len(vectorizer.get_feature_names_out()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9006685768863419\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.98      0.95      1895\n",
      "           1       0.44      0.18      0.26       199\n",
      "\n",
      "    accuracy                           0.90      2094\n",
      "   macro avg       0.68      0.58      0.60      2094\n",
      "weighted avg       0.87      0.90      0.88      2094\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[1850   45]\n",
      " [ 163   36]]\n"
     ]
    }
   ],
   "source": [
    "# Train Logistic Regression Model\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train_bow, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = clf.predict(X_test_bow)\n",
    "\n",
    "# Evaluate model\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Misclassified Example:\n",
      "Text: christmas celebration birth merely child child changed destiny humans forever celebration fact god wanted part human race took flesh blood became human like us also show unconditional love good deeds helping need help care human merciful\n",
      "Original Text: Christmas is celebration of the birth of not merely a child , but a child who changed the destiny of humans forever . It is celebration of the fact that God wanted to be a part of the human race and so he took on flesh and blood and became human like us . We can also show unconditional love through our good deeds and helping those who are in need of our help and care . Be human and merciful .\n",
      "True Label: 0\n",
      "Predicted Label: 1\n"
     ]
    }
   ],
   "source": [
    "# Get misclassified examples\n",
    "df_test = X_test.reset_index(drop=True).to_frame()\n",
    "df_test[\"true_label\"] = y_test.reset_index(drop=True)\n",
    "df_test[\"predicted_label\"] = y_pred\n",
    "\n",
    "misclassified = df_test[df_test[\"processed_text\"] == test_df[test_df[\"par_id\"] == 9423][\"processed_text\"].values[0]]\n",
    "\n",
    "\n",
    "if not misclassified.empty:\n",
    "    example = misclassified.sample(1)  # Pick a random misclassified example\n",
    "    print(\"\\nMisclassified Example:\")\n",
    "    print(\"Text:\", example[\"processed_text\"].values[0])\n",
    "    print(\"Original Text:\", test_df.loc[example.index[0], \"text\"])\n",
    "    print(\"True Label:\", example[\"true_label\"].values[0])\n",
    "    print(\"Predicted Label:\", example[\"predicted_label\"].values[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average 'helping' count for class 0: 0.006463527239150508\n",
      "Average 'helping' count for class 1: 0.03526448362720403\n",
      "\n",
      "Average 'help' count for class 0: 0.04141933781822978\n",
      "Average 'help' count for class 1: 0.13350125944584382\n",
      "\n",
      "Average 'love' count for class 0: 0.009233610341643583\n",
      "Average 'love' count for class 1: 0.022670025188916875\n",
      "\n",
      "Average 'fact' count for class 0: 0.013190871916633689\n",
      "Average 'fact' count for class 1: 0.011335012594458438\n",
      "\n",
      "Average 'christmas' count for class 0: 0.001319087191663369\n",
      "Average 'christmas' count for class 1: 0.031486146095717885\n"
     ]
    }
   ],
   "source": [
    "# Find how often the word 'help' appears per-class\n",
    "word_index = vectorizer.vocabulary_['helping']\n",
    "word_counts = X_train_bow[:, word_index].toarray().flatten()\n",
    "train_df[\"helping_count\"] = word_counts\n",
    "print(\"\\nAverage 'helping' count for class 0:\", train_df[train_df[\"label\"] == 0][\"helping_count\"].mean())\n",
    "print(\"Average 'helping' count for class 1:\", train_df[train_df[\"label\"] == 1][\"helping_count\"].mean())\n",
    "\n",
    "word_index = vectorizer.vocabulary_['help']\n",
    "word_counts = X_train_bow[:, word_index].toarray().flatten()\n",
    "train_df[\"help_count\"] = word_counts\n",
    "print(\"\\nAverage 'help' count for class 0:\", train_df[train_df[\"label\"] == 0][\"help_count\"].mean())\n",
    "print(\"Average 'help' count for class 1:\", train_df[train_df[\"label\"] == 1][\"help_count\"].mean())\n",
    "\n",
    "word_index = vectorizer.vocabulary_['love']\n",
    "word_counts = X_train_bow[:, word_index].toarray().flatten()\n",
    "train_df[\"love_count\"] = word_counts\n",
    "print(\"\\nAverage 'love' count for class 0:\", train_df[train_df[\"label\"] == 0][\"love_count\"].mean())\n",
    "print(\"Average 'love' count for class 1:\", train_df[train_df[\"label\"] == 1][\"love_count\"].mean())\n",
    "\n",
    "word_index = vectorizer.vocabulary_['fact']\n",
    "word_counts = X_train_bow[:, word_index].toarray().flatten()\n",
    "train_df[\"fact_count\"] = word_counts\n",
    "print(\"\\nAverage 'fact' count for class 0:\", train_df[train_df[\"label\"] == 0][\"fact_count\"].mean())\n",
    "print(\"Average 'fact' count for class 1:\", train_df[train_df[\"label\"] == 1][\"fact_count\"].mean())\n",
    "\n",
    "word_index = vectorizer.vocabulary_['christmas']\n",
    "word_counts = X_train_bow[:, word_index].toarray().flatten()\n",
    "train_df[\"christmas_count\"] = word_counts\n",
    "print(\"\\nAverage 'christmas' count for class 0:\", train_df[train_df[\"label\"] == 0][\"christmas_count\"].mean())\n",
    "print(\"Average 'christmas' count for class 1:\", train_df[train_df[\"label\"] == 1][\"christmas_count\"].mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Misclassified Example:\n",
    "Text: christmas celebration birth merely child child changed destiny humans forever celebration fact god wanted part human race took flesh blood became human like us also show unconditional love good deeds helping need help care human merciful\n",
    "Original Text: Christmas is celebration of the birth of not merely a child , but a child who changed the destiny of humans forever . It is celebration of the fact that God wanted to be a part of the human race and so he took on flesh and blood and became human like us . We can also show unconditional love through our good deeds and helping those who are in need of our help and care . Be human and merciful .\n",
    "True Label: 0\n",
    "Predicted Label: 1\n",
    "\n",
    "this example has original label (0,0) meaning two annotators marked it as non-PCL."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
